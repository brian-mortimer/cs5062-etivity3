{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed370d8a",
   "metadata": {},
   "source": [
    "# Etivity 3 - Task 2: Regression\n",
    "## Name: Brian Mortimer\n",
    "## Student ID: 20258763"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30b34d",
   "metadata": {},
   "source": [
    "Open a new Jupyter notebook and name it etivity3_regression.ipynb. In this notebook, train three regression pipelines with Random Forest, Linear Regression and a third regressor of your choice as the final estimator, respectively, for predicting the value of `insurance_cost`.\n",
    "\n",
    "Requirements:\n",
    "- For each regressor, include data preparation and dimensionality reduction steps in the main pipeline.\n",
    "- You can choose any regressor as the third one. Some options are SVR and MLPRegressor, but you are not limited to them.\n",
    "- For the dimensionality reduction step use PCA, RFE and a third dimensionality reduction (incl. feature selection) technique in at least one pipeline.\n",
    "- Use grid search for hyperparameter tuning and replicate the process in the example notebook Tutorial 3-2 - Regression and Dimensionality Reduction.ipynb to evaluate and compare the models you have trained and pick the best one.\n",
    "- Summarise your experience in a markdown cell (max 150 words in a markdown cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99bcf3e",
   "metadata": {},
   "source": [
    "### Data Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cebc299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import (ColumnTransformer, TransformedTargetRegressor)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn import set_config\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b16927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def load_insurance_data():\n",
    "    \"\"\"\n",
    "    Load the insurance dataset from a CSV file.\n",
    "    Returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv('insurance.csv')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b883e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>insurance_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>34.100</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1137.01100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>26.315</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2198.18985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>38.665</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>3393.35635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>35.625</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2211.13075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender     bmi  children smoker     region  insurance_cost\n",
       "0   18    male  33.770         1     no  southeast      1725.55230\n",
       "1   18    male  34.100         0     no  southeast      1137.01100\n",
       "2   18  female  26.315         0     no  northeast      2198.18985\n",
       "3   18  female  38.665         2     no  northeast      3393.35635\n",
       "4   18  female  35.625         0     no  northeast      2211.13075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_original = load_insurance_data()\n",
    "df = df_original.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458d76b3",
   "metadata": {},
   "source": [
    "### Define Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21eba328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers\n",
    "# Transform gender to binary values \"male\"=0, \"female\"=1\n",
    "gender_transformer = FunctionTransformer(\n",
    "    lambda x: np.where(x == 'male', 0, 1)\n",
    ")\n",
    "\n",
    "# Transform region to binary values \"northeast\"=0, \"southeast\"=1, \"southwest\"=2, \"northwest\"=3\n",
    "region_transformer = FunctionTransformer(\n",
    "    lambda x: pd.get_dummies(x, drop_first=True)\n",
    ")\n",
    "\n",
    "# Transform smoker to binary values \"yes\"=1, \"no\"=0\n",
    "smoker_transformer = FunctionTransformer(\n",
    "    lambda x: np.where(x == 'yes', 1, 0)\n",
    ")\n",
    "\n",
    "# Transform BMI using log transformation to reduce skewness and impact of outliers\n",
    "bmi_transformer  = Pipeline(\n",
    "    steps=[\n",
    "        (\"log_transform\", FunctionTransformer(np.log)), \n",
    "        (\"scaler\", RobustScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Transform children using cubic root transformation to reduce skewness\n",
    "children_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"cubic_root_transform\", FunctionTransformer(np.cbrt)),\n",
    "        (\"scaler\", RobustScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bmi', bmi_transformer, ['bmi']),\n",
    "        ('age', StandardScaler(), ['age']),\n",
    "        ('children', children_transformer, ['children']),\n",
    "        ('gender', gender_transformer, ['gender']),\n",
    "        ('region', region_transformer, ['region']),\n",
    "        ('smoker', smoker_transformer, ['smoker'])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6500fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target variable\n",
    "X = df.drop(columns=['insurance_cost'])\n",
    "y = df['insurance_cost']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cba69",
   "metadata": {},
   "source": [
    "### Define & Optimise Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31244cd3",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b2ec159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model pipeline for a Random Forest Regressor\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    (\"reduce_dim\", \"passthrough\"),\n",
    "    ('ttr', TransformedTargetRegressor(\n",
    "        regressor=RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=10),\n",
    "        func=np.log,\n",
    "        inverse_func=np.exp\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324b19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.852:\n",
      "Best parameters:  {'reduce_dim': 'passthrough', 'ttr__regressor__max_depth': 6, 'ttr__regressor__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "20 fits failed out of a total of 260.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 468, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "                                    ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 542, in _fit\n",
      "    return self._fit_full(X, n_components, xp, is_array_api_compliant)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 556, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=10 must be between 0 and min(n_samples, n_features)=8 with svd_solver='covariance_eigh'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Brian\\anaconda3\\envs\\ai_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-1.52389415e-03  4.91838983e-03 -1.68644352e-02 -3.97312309e-02\n",
      " -5.07130705e-05  9.23088647e-02  1.58637898e-01  2.06369627e-01\n",
      "  1.15799801e-02  1.33954721e-01  2.06905766e-01  2.62824551e-01\n",
      "  7.55690269e-01  8.22156089e-01  8.24793952e-01  8.24179309e-01\n",
      "             nan             nan             nan             nan\n",
      "  7.41177344e-01  7.46084012e-01  7.37971957e-01  7.28939810e-01\n",
      "  8.05000015e-01  8.51242235e-01  8.49591591e-01  8.44988798e-01\n",
      "  8.05000015e-01  8.51102304e-01  8.48603335e-01  8.41495481e-01\n",
      "  8.05000015e-01  8.51120859e-01  8.49009614e-01  8.43680308e-01\n",
      "  8.05000015e-01  8.51120859e-01  8.49009614e-01  8.43680308e-01\n",
      "  8.05000015e-01  8.05715952e-01  8.05592144e-01  8.51120859e-01\n",
      "  8.51455741e-01  8.51421267e-01  8.49009614e-01  8.52379944e-01\n",
      "  8.52419792e-01  8.43680308e-01  8.50928872e-01  8.50689911e-01]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [2, 4, 6, 8, 10]\n",
    "MAX_DEPTH_OPTIONS = [2, 4, 6, 8]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'ttr__regressor__max_depth': MAX_DEPTH_OPTIONS,\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(RandomForestRegressor(random_state=42, n_jobs=-1))],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'ttr__regressor__max_depth': MAX_DEPTH_OPTIONS,\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [\"passthrough\"],\n",
    "        'ttr__regressor__n_estimators': [10, 50, 100],\n",
    "        'ttr__regressor__max_depth': MAX_DEPTH_OPTIONS,\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(rf_pipeline, param_grid, n_jobs=-1, cv=5, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "RF_best_params = search.best_params_\n",
    "RF_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979675a",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd3e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43bd5a40",
   "metadata": {},
   "source": [
    "#### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68223c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71d92fa",
   "metadata": {},
   "source": [
    "### Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3537846",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
